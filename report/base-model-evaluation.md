## Base model evaluation
timestamp: 2025-11-29 02:14:42

- Model: base_model (step 21400)
- CORE metric: 0.1710
- hellaswag_zeroshot: 0.2364
- jeopardy: 0.0487
- bigbench_qa_wikidata: 0.4287
- arc_easy: 0.4815
- arc_challenge: 0.1217
- copa: 0.2800
- commonsense_qa: 0.0469
- piqa: 0.3308
- openbook_qa: 0.1173
- lambada_openai: 0.3346
- hellaswag: 0.2348
- winograd: 0.2161
- winogrande: 0.0450
- bigbench_dyck_languages: 0.1240
- agi_eval_lsat_ar: 0.0543
- bigbench_cs_algorithms: 0.3962
- bigbench_operators: 0.1381
- bigbench_repeat_copy_logic: 0.0000
- squad: 0.1213
- coqa: 0.1469
- boolq: -0.3182
- bigbench_language_identification: 0.1759

